# Project 4: Team Git Hackathon

Pick a Kaggle competition from the following list. You have the choice of completing a regression problem, a classification problem, or an NLP problem involving either classification or sentiment analysis.

## Options
### Regression
- [Restaurant Revenue Prediction](https://www.kaggle.com/c/restaurant-revenue-prediction)
- [Walmart Store Sales Forecasting](https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting)
- [Box Office Revenue Prediction](https://www.kaggle.com/c/tmdb-box-office-prediction)
- [New York City Taxi Fare Prediction](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction)

### Classification
- [Predicting a Biological Response](https://www.kaggle.com/c/bioresponse/data)
- [Kobe Bryant Shot Selection](https://www.kaggle.com/c/kobe-bryant-shot-selection)
- [Shelter Animal Outcomes](https://www.kaggle.com/c/shelter-animal-outcomes)
- [Airbnb New User Bookings](https://www.kaggle.com/c/airbnb-recruiting-new-user-bookings)

### NLP
- [Sentiment Analysis on Movie Reviews](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews)
- [What's Cooking?](https://www.kaggle.com/c/whats-cooking)
- [Real or Not? NLP with Disaster Tweets](https://www.kaggle.com/c/nlp-getting-started/)

## Timeline
- **9:00am** - Project introduction & team assignment
- **10:00am** - Slack Hov/Charlie what competition/dataset you've chosen (only one person needs to do this). Make sure the entire group is satisfied with the choice.
- **4:00pm** - Submit a link to your project repository on Google classroom (only one partner needs to do this). You are also encouraged to submit your predictions to Kaggle as well (you can make a late submission if the competition is closed) and see how you did!
- **4:30pm** - We will do lightning talks where you'll walk the rest of the class through your problem solving process and what you completed. No slides necessary; you can walk us through your Jupyter notebook if you prefer.
- **5:00pm** - Complete the reflection form on Google Classroom (ALL teammates need to do this).

## Guidelines

We know this is a short time for a project. We're not expecting anything as polished as project two or three, for example. However, the goal is for you to have something to show for your time, especially in terms of pull requests, and merges. At a minimum, do some EDA and have at least one model fit and scored.

## Rubric

*Scores will be out of 21 points based on the 7 categories in the rubric.** <br>
*3 points per section*<br>

| Score | Interpretation |
| --- | --- |
| **0** | *Project fails to meet the minimum requirements for this item.* |
| **1** | *Project meets the minimum requirements for this item, but falls significantly short of portfolio-ready expectations.* |
| **2** | *Project exceeds the minimum requirements for this item, but falls short of portfolio-ready expectations.* |
| **3** | *Project meets or exceeds portfolio-ready expectations; demonstrates a thorough understanding of every outlined consideration.* |

**Data Cleaning and EDA**
- Are missing values imputed/handled appropriately?
- Are distributions examined and described?
- Are outliers identified and addressed?
- Are appropriate summary statistics provided?
- Are steps taken during data cleaning and EDA framed appropriately?

**Visualizations**
- Are sufficient visualizations provided?
- Do plots accurately demonstrate valid relationships?
- Are plots labeled properly?
- Are plots interpreted appropriately?
- Are plots formatted and scaled appropriately for inclusion in a notebook-based technical report?

**Preprocessing and Modeling**
- Are categorical variables appropriately handled?
- Does the student properly split and/or sample the data for validation/training purposes?
- Does the student utilize feature selection to remove noisy or multi-collinear features?
- Does the student test and evaluate a variety of models to identify a production algorithm?
- Does the student defend their choice of production model relevant to the data at hand and the problem?
- Does the student explain how the model works and evaluate its performance successes/downfalls?

**Evaluation and Conceptual Understanding**
- Does the student accurately identify and explain the baseline score?
- Does the student select and use metrics relevant to the problem objective?
- Does the student interpret the results of their model for purposes of inference?
- Is domain knowledge demonstrated when interpreting results?

**Project Organization**
- Are modules imported correctly (using appropriate aliases)?
- Does the README provide a good executive summary of the project?
- Is markdown formatting used appropriately to structure notebooks?
- Are there an appropriate amount of comments to support the code?
- Are files & directories organized correctly?
- Are there unnecessary files included?
- Do files and directories have well-structured, appropriate, consistent names?

**Python Syntax and Control Flow**
- Is care taken to write human readable code?
- Is the code syntactically correct (no runtime errors)?
- Does the code generate desired results (logically correct)?
- Does the code follows general best practices and style guidelines?
- Are Pandas and sklearn functions used appropriately?

**Teamwork**  
- How is the student's self-rating for teamwork?
- How is the student's rating for teamwork from their partner?
- How is the student's self-rating for data science skills?
- How is the student's rating for data science skills from their partner?
- Did the student put in effort throughout the project?
- Was the work evenly distributed?

## Note

Do not duplicate someone else's analysis and make sure to give credit to any resources you used. :)

## Have fun!
